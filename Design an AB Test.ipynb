{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Overview: Free Trial Screener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of this experiment, Udacity courses currently have two options on the home page: \"start free trial\", and \"access course materials\". If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n",
    "\n",
    "\n",
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead.\n",
    "\n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time—without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invariant metrcis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Number of cookies* (number of unique cookies to view the course overview page)\n",
    "2. *Number of clicks* (number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Gross conversion*  (number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button) \n",
    "2. *Net conversion* (number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button)\n",
    "\n",
    "\n",
    "* Number of cookies is chosen as an invariant metric because viewing of the course overview page happens before experiment and is not changed by the experiment. Plus, a cookie is a unit of diversion by which we separate users into control and experiment groups therefore the number of cookies should be even in both groups.\n",
    "* Number of user-ids is neither invariant nor evaluation metric for the experiment. It is the number of users who enroll in a free trial and it is dependent on the experiment. Moreover, it is not tracked if the user does not enroll in a free trial and therefore number of user ids-will be different between the control and the experiment groups which may skew the result of the experiment.\n",
    "* Number of clicks is an invariant metric. Clicking on the \"Start free trial\" button happens before the experiment and is not dependent on it.\n",
    "* Click-through-probability even though can be a good invariant metric I have not chosen it. Basically, click-through-probability is a fraction of number of clicks in number of cookies which as stated above have already been choses as invariant metrics themselves. Both viewing of course page and clicking “Start free trial\" button happen before the experiment and is are not influenced by the experiment.\n",
    "* Gross conversion is an evaluation metric in the experiment. It represents the fraction of users who enrolled in the trial in the total number of users who clicked the \"Start free trial\" button and is dependent on the experiment and therefore cannot be an invariant metric. Gross conversion is a good evaluation metric because it will show if the experiment led to decreasing costs for Udacity.\n",
    "* Retention can be an evaluation metric. It is not invariant metric because the number of user who enroll in a free trial is directly dependent on the experiment. It is a good evaluation metric since positive change in the metric will mean that the experiment led to increase in paying customers and therefore increase in the revenue. However, I have chosen not to use it since it will require a huge amount of pageviews to power the experiment if Retention is used as an evaluation metric.\n",
    "* Net conversion is an evaluation metric and not invariant because the number of user who enroll in the trial is dependent on the experiment. It is a good evaluation metric since positive change in this metric means increase of revenue for Udacity.\n",
    "\n",
    "To launch the experiment, I will need Gross conversion to have practically significant decrease. I am expecting to have gross conversion rate lower in the experiment group because if hypnosis holds experiment should prevent users who do not have enough time to commit to the course from enrolling and therefore decreasing cost for Udacity.\n",
    "\n",
    "Net conversion on the other hand is required to have statistically significant increase. I expect net conversion to be higher in the experiment group since users in this group are aware of what it requires to finish the course and more likely to continue after the trial is over which will lead to increase in revenue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross Conversion standard error:  0.0202\n",
      "Net Conversion standard error:  0.0156\n",
      "Retention standard error:  0.0549\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Sample number of cookies visiting the course overview page:\n",
    "N_sample = 5000.0\n",
    "#Unique cookies to view page per day:\n",
    "N_unique = 40000.0\n",
    "#Unique cookies to click \"Start free trial\" per day:\n",
    "n_click = 3200.0\n",
    "#Enrollments per day:\n",
    "n_enr = 660\n",
    "#Probability of enrolling, given click:\n",
    "p_enr_click = 0.20625\n",
    "#Probability of payment, given enroll:\n",
    "p_pay_enr = 0.53\n",
    "#Probability of payment, given click\n",
    "p_pay_click = 0.1093125\n",
    "\n",
    "#Click through probability\n",
    "ctp = n_click/N_unique\n",
    "\n",
    "#Probability of enrolling given pageview.\n",
    "p_enr_view= n_enr/N_unique\n",
    "\n",
    "#Gross Conversion standard deviation calcualtion:\n",
    "SE_gc = math.sqrt(p_enr_click * (1-p_enr_click)/(ctp*N_sample))\n",
    "\n",
    "#Net Conversion standard deviation calcualtion:\n",
    "SE_nc = math.sqrt(p_pay_click * (1-p_pay_click)/(ctp*N_sample))\n",
    "\n",
    "#Retention standard deviation calcualtion:\n",
    "SE_ret = math.sqrt(p_pay_enr * (1-p_pay_enr)/(p_enr_view*N_sample))\n",
    "\n",
    "print \"Gross Conversion standard error: \", round(SE_gc,4)\n",
    "print \"Net Conversion standard error: \", round(SE_nc,4)\n",
    "print \"Retention standard error: \", round(SE_ret,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Gross conversion and Net conversion have a unit of diversion (number of cookies) as denominator therefore the analytic estimate would be comparable to the the empirical variability.\n",
    "\n",
    "For Retention unit of analysis (number of users who complete checkout) is different form the unit of diversion therefore analytical and empirical estimates would be different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizing\n",
    "### Choosing Number of Samples given Power\n",
    "\n",
    "I am not using Bonferroni correction because metrics are correlated and the correction will be too ocnservative. \n",
    "\n",
    "Using [this online calculator](http://www.evanmiller.org/ab-testing/sample-size.html) I got the number of pageviews needed for the experiment (using alpha = 0.05 and beta = 0.2):\n",
    "\n",
    "**For Gross Conversion** (baseline conversion rate = Probability of Enrolling given Click = 20.625% and dmin = 0.01): 25,835 samples.\n",
    "\n",
    "**For Net Conversion** (baseline conversion rate = Probability of Payment given Click = 10.93125% and dmin = 0.0075): 27,413 samples.\n",
    "\n",
    "**For Retention** (baseline conversion rate = Probability of Payment given Enrollment = 53% and dmin = 0.01): 39,087 samples.\n",
    "\n",
    "Click through probability is 0.08 meaning only 0.08 pageviews lead to click. Probability of enrolling given pageview is 0.0165. Also, we need double the size since we need total pageviews for both control and experiment groups.\n",
    "\n",
    "Therefore, pageviews needed for \n",
    "\n",
    "**Gross Conversion** = (25,835/0.08) $*$ 2 = 645,875. \n",
    "**Net Conversion**  = (27,413/0.08) $*$ 2 = 685,325.\n",
    "**Retention** = (39,087/0.0165) $*$ 2 = 4,737,818\n",
    "\n",
    "Retention requires too many pageviews so I am removing it from consideration as evaluation metric leaving only Gross and Net Conversion metrics. \n",
    "Therefore picking the highest number of pageviews from Gross Conversion and Net Conversion I conclude that 685,325 pageviews are needed to power the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Duration vs. Exposure\n",
    "\n",
    "I would divert 80% of Udacity's traffic to this experiment which means approximately 22 days (685,325 pageviews needed / (40,000  $*$ 0.8 Unique cookies to view page per day)) are needed for the experiment. This is about 3 weeks which is enough to cover both weekdays and weekends in the case of traffic being much different between weekdays and weekends.\n",
    "\n",
    "The change that experiment assumes is low risk. It will not affect any Udacity's content or existing customers also even though it might discourage new enrolments it can reduce Udacity's cost. Moreover, the experiment setup is just suggesting new users not to enroll if they not have enough time to dedicate but it does not prevent users from enrolling they still can ignore the warning and proceed to enrolment.\n",
    "\n",
    "However, I will not divert 100% of the traffic to the experiment just in case of a possible bug in the experiment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Analysis\n",
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cookies\n",
      "Confidence interval lower bound: 0.498820392149\n",
      "Confidence interval upper bound: 0.501179607851\n",
      "Observed: 0.500639666881\n",
      "\n",
      "\n",
      "Number of Clicks\n",
      "Confidence interval lower bound: 0.495884495724\n",
      "Confidence interval upper bound: 0.504115504276\n",
      "Observed: 0.500467347407\n"
     ]
    }
   ],
   "source": [
    "# Total pageviews for Control group\n",
    "N_pv_control = 345543.0\n",
    "# Total pageviews for Experiment group\n",
    "N_pv_exp = 344660.0\n",
    "# Total pageviews\n",
    "N_pv_total = 690203.0\n",
    "# Probability of being in control or experiment\n",
    "p = 0.5\n",
    "\n",
    "# Total clicks for Control group\n",
    "N_c_control = 28378.0\n",
    "# Total clicks for Experiment group\n",
    "N_c_exp = 28325.0\n",
    "# Total clicks\n",
    "N_c_total = 56703.0\n",
    "\n",
    "## For Number of Cookies\n",
    "SE_cookies = math.sqrt(p * (1-p)* (1/(N_pv_control + N_pv_exp)))\n",
    "me_cookies = SE_cookies * 1.96\n",
    "print \"Number of Cookies\"\n",
    "print \"Confidence interval lower bound:\", p-me_cookies\n",
    "print \"Confidence interval upper bound:\", p+me_cookies\n",
    "print \"Observed:\", N_pv_control/N_pv_total\n",
    "\n",
    "print \"\\n\"\n",
    "## For Number of Clicks\n",
    "SE_clicks = math.sqrt(p * (1-p)* (1/(N_c_control + N_c_exp)))\n",
    "me_clicks = SE_clicks * 1.96\n",
    "print \"Number of Clicks\"\n",
    "print \"Confidence interval lower bound:\", p-me_clicks\n",
    "print \"Confidence interval upper bound:\", p+me_clicks\n",
    "print \"Observed:\", N_c_control/N_c_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both invariant metrics pass sanity check (observed value is with the confidence interval) therefore we can proceed to result analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis\n",
    "\n",
    "### Effect Size Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross Conversion:\n",
      "Difference: -0.0205548745804\n",
      "Confidence interval lower bound: -0.0291233583354\n",
      "Confidence interval upper bound: -0.0119863908253\n"
     ]
    }
   ],
   "source": [
    "#  Number of clicks for control group\n",
    "N_click_control = 17293.0\n",
    "#  Number of clicks for experiment group\n",
    "N_click_exp = 17260.0\n",
    "\n",
    "#  Number of enrollments for control group\n",
    "N_enr_control = 3785.0\n",
    "#  Number of enrollments for experiment group\n",
    "N_enr_exp = 3423.0\n",
    "gross_conversion_control  = N_enr_control/N_click_control\n",
    "gross_conversion_exp  = N_enr_exp/N_click_exp\n",
    "\n",
    "pooled_prob = (N_enr_control+N_enr_exp)/(N_click_control+N_click_exp)\n",
    "pooled_se = math.sqrt(pooled_prob*(1-pooled_prob)*(1/N_click_control+ 1/N_click_exp))\n",
    "\n",
    "d_min = 0.01 \n",
    "\n",
    "diff = gross_conversion_exp - gross_conversion_control\n",
    "\n",
    "me_gc = pooled_se * 1.96\n",
    "\n",
    "print \"Gross Conversion:\"\n",
    "print \"Difference:\", diff\n",
    "print \"Confidence interval lower bound:\", diff-me_gc \n",
    "print \"Confidence interval upper bound:\", diff+me_gc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gross Conversion is statistically significant: it's confidence interval does not include zero (that is we can be confident that there was a change). Also, the metric is practically significant: it's confidence interval does not include significance boundary 0.01 (that is, we can be confident there is a change that matters to Udacity.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Conversion:\n",
      "Difference: -0.00487372267454\n",
      "Confidence interval lower bound: -0.0116046243599\n",
      "Confidence interval upper bound: 0.0018571790108\n"
     ]
    }
   ],
   "source": [
    "#  Number of enrollments >14 days for control group\n",
    "N_enr14_control = 2033.0\n",
    "#  Number of enrollments >14 days for experiment group\n",
    "N_enr14_exp = 1945.0\n",
    "\n",
    "net_conversion_control  = N_enr14_control/N_click_control\n",
    "net_conversion_exp  = N_enr14_exp/N_click_exp\n",
    "\n",
    "pooled_prob = (N_enr14_control+N_enr14_exp)/(N_click_control+N_click_exp)\n",
    "pooled_se = math.sqrt(pooled_prob*(1-pooled_prob)*(1/N_click_control+ 1/N_click_exp))\n",
    "\n",
    "d_min = 0.0075\n",
    "\n",
    "diff = net_conversion_exp - net_conversion_control\n",
    "\n",
    "me_nc = pooled_se * 1.96\n",
    "\n",
    "print \"Net Conversion:\"\n",
    "print \"Difference:\", diff\n",
    "print \"Confidence interval lower bound:\", diff-me_nc  \n",
    "print \"Confidence interval upper bound:\", diff+me_nc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net Conversion is not statistically significant: it's confidence interval includes zero. It means that it is unlikely that there was a real difference. Also, the metric is not practically significant: it's confidence interval includes significance boundary -0.0075.\n",
    "\n",
    "### Sign Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [this online calculator](http://graphpad.com/quickcalcs/binomial1.cfm) I got p value for the sign test as follows:\n",
    "\n",
    "**Gross Conversion** (with 4 successes out of 23 trials): 0.0026 p value - statisitically siginificant (0.0026 < 0.05)\n",
    "\n",
    "**Net Conversion**  (with 10 successes out of 23 trials): 0.6776 - not statisitically siginificant (0.6776 < 0.05)\n",
    "\n",
    "### Summary\n",
    "\n",
    "I have not used Bonferroni correction because metrics are correlated and the correction will be too conservative. Also, the correction is used when we are looking for either of our metrics to meet our expectations for the launch we need both Gross Retention and Net Retention to meet the expectations and not only one of them.\n",
    "\n",
    "There is are discrepancies between the effect size hypothesis tests and the sign tests. Both tests show that Gross Conversion is statistically significant while Net Conversion is not statistically significant.\n",
    "\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "My recommendation is not to launch the experiment as is. \n",
    "\n",
    "We were looking at 2 evaluation metrics: Gross and Net Conversion. While Gross conversion resulted in being both statistically significant and practically significant, and was negative meaning the experiment would discourage people who do not have enough time from signing up resulting in lower cost for Udacity; Net conversion appeared to be neither statistically nor practically significant and negative which means that the number of enrollments staying enrolled past 14 days and paying went down decreasing Udacity’s revenue.\n",
    "The experiment fails the goal of increasing the number of paid users therefore am recommending not to launch it as is and look for other ways to prevent not serious users from signing up for the trial.\n",
    "\n",
    "\n",
    "\n",
    "# Follow-Up Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that one of the reasons people might cancel after a free trial is because they do not have enough skills or prior knowledge to continue with the course and they get discouraged.\n",
    "\n",
    "As an experiment, I propose have in a skill test in the 14-day trial period that assess the required prerequisite knowledge and skills. After the user passes the test the results will show up and suggest to either go further with the course (if test was passed) or direct the user to supporting free courses that will prepare him/her to take a paid course.\n",
    "Having a skill test in a free trial or not will be assigned at a random for users after they have completed a check-out for the free trial.\n",
    "\n",
    "The **Null Hypothesis** for my experiment is: adding a skill test will not significantly increase retention. The **Alterative Hypothesis**: that adding a skill test will significantly increase retention.\n",
    "\n",
    "User id may be used both as a **unit of diversion and an invariant metric**. It is a good invariant metric and unit of diversion because the number of user ids is not dependent on the experiment since experiment starts after the user sings up for the trial and gets assigned a user id.\n",
    "\n",
    "Retention (number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout) is a good **evaluation metric** in this case. To launch the change we want to see retention having statistical and practical increase.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
